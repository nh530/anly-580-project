{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "#### Norman Hong, Ryan Callahan, Nora Wu and Masha Gubenko\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 Exploratory Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blocks below summarize statistical characteristics of the dev and gold datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import re \n",
    "from statistics import stdev\n",
    "import pandas as pd \n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from math import log\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import nltk \n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Read in the data\n",
    "data = pd.read_csv(\"Dev/INPUT.txt\", sep='\\t', header=None, \n",
    "                   names=['id', 'target', 'tweet'], encoding='utf-8')\n",
    "data.drop(['id', 'target'], axis=1, inplace=True)\n",
    "\n",
    "# Tokenize\n",
    "regexes=(\n",
    "# Keep usernames together (any token starting with @, followed by A-Z, a-z, 0-9)        \n",
    "r\"(?:@[\\w_]+)\",\n",
    "            \n",
    "# Keep hashtags together (any token starting with #, followed by A-Z, a-z, 0-9, _, or -)\n",
    "r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\",\n",
    "\n",
    "# abbreviations, e.g. U.S.A.\n",
    "r'(?:[A-Z]\\.)+',\n",
    "r'[A-Za-z]\\.(?:[A-Za-z0-9]\\.)+',\n",
    "r'[A-Z][bcdfghj-np-tvxz]+\\.',\n",
    "\n",
    "# URL, e.g. https://google.com\n",
    "r'https?:\\/\\/(?:www\\.',\n",
    "r'(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}',\n",
    "r'www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}',\n",
    "r'https?:\\/\\/(?:www\\.',\n",
    "r'(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}',\n",
    "r'www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}',\n",
    "\n",
    "# Currency and percentages, e.g. $12.40, 82%\n",
    "r'\\$?\\d+(?:\\.\\d+)?%?',\n",
    "\n",
    "# Numbers i.e. 123,56.34\n",
    "r'(?:[0-9]+[,]?)+(?:[.][0-9]+)?',\n",
    "\n",
    "# Keep words with apostrophes, hyphens, and underscores together\n",
    "r\"(?:[a-z][a-zâ€™'\\-_]+[a-z])\",\n",
    "\n",
    "# Keep all other sequences of A-Z, a-z, 0-9, _ together\n",
    "r\"(?:[\\w_]+)\",\n",
    "\n",
    "# Match words at the end of a sentence.  e.g. tree. or tree!\n",
    "r'(?:[a-z]+(?=[.!\\?]))',\n",
    "\n",
    "# Everything else that's not whitespace\n",
    "# It seems like this captures punctuations and emojis and emoticons.  \n",
    "#r\"(?:\\S)\"\n",
    ")\n",
    "\n",
    "big_regex=\"|\".join(regexes)\n",
    "my_extensible_tokenizer = re.compile(big_regex, re.VERBOSE | re.I | re.UNICODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Input Data\n",
    "Total number of tweets is 11,906.  \n",
    "Total number of characters is 1,354,375.  \n",
    "Total number of distinct words (vocabulary) is 41,760.  \n",
    "Average number of words and characters per tweet is 16.066 and 113.756, respectively.  \n",
    "Average number and standard deviation of characters and token 5.979 and 4.706. \n",
    "Total tokens corresponding to 10 most frequent words is 23,268.  \n",
    "Number of distinct word n-grams for n=2,3,4,5:\n",
    "- n-2: 130,116\n",
    "- n-3: 157,675\n",
    "- n-4: 153,193\n",
    "- n-5: 142,858\n",
    "\n",
    "Number of distinct character n-grams for n=2,3,4,5,6,7:\n",
    "- n-2: 8,069\n",
    "- n-3: 98,192\n",
    "- n-4: 212,264\n",
    "- n-5: 361,987\n",
    "- n-6: 520,197\n",
    "- n-7: 662,468   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Total number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets: 11906\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tweets: \" + str(data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. The total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters, including spaces: 1354375\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for tweet in data.values:\n",
    "    # Add to total character count\n",
    "    num += len(tweet[0])\n",
    "print(\"Total number of characters, including spaces: \" + str(num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. The total number of distinct words (vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words: 41760\n"
     ]
    }
   ],
   "source": [
    "# Define list that will hold all tokens\n",
    "temp = []\n",
    "\n",
    "# Iterate through each tweet\n",
    "for text in data.values:\n",
    "    # Each time the REGEX matches, add the matched string to the running list of all words\n",
    "    for matches in my_extensible_tokenizer.findall(text[0]):       \n",
    "         #just in case get empty matches\n",
    "        if matches != '':\n",
    "            # Add string to master list\n",
    "            temp.append(matches)\n",
    "            \n",
    "# Define dictionary that will hold counts of all distinct tokens\n",
    "corpus = {}\n",
    "\n",
    "# Define variable that will hold counts of each word length\n",
    "lengths = []\n",
    "\n",
    "# Looking through entire list of (repeated) words, count instances of distinct words\n",
    "for word in temp:\n",
    "    # Add character count (non-whitespace) to counting list\n",
    "    lengths.append(len(word))\n",
    "    # If word has already been seen, add one to its count\n",
    "    if word in corpus:\n",
    "        corpus[word] += 1\n",
    "    # If word has not already been seen, add word to list\n",
    "    else:\n",
    "        corpus[word] = 1\n",
    "        \n",
    "## temp contains urls, which are included in the count.  \n",
    "## Are urls really words?\n",
    "print(\"Number of distinct words: \" + str(len(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. The average number of characters and words in each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avgerage number of words per tweet is 16.065765160423314\n",
      "Average number of characters per tweet is113.75566941038132\n"
     ]
    }
   ],
   "source": [
    "print(\"Avgerage number of words per tweet is \" + str(len(temp)/data.shape[0]))\n",
    "data[\"characters\"] = 0\n",
    "# Write character count of each tweet to the character count column\n",
    "data[\"characters\"] = data[\"tweet\"].str.len()\n",
    "print(\"Average number of characters per tweet is\" + str(data[\"characters\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. The average number and standard deviation of characters per token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of characters per token: 5.969850323349662\n",
      "Standard deviation of characters per token: 4.705890651698625\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of characters per token: \" + str(sum(lengths)/len(temp)))\n",
    "print(\"Standard deviation of characters per token: \" + str(stdev(lengths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. The total number of tokens corresponding to the top 10 most frequent words (types) in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of times that 10 most popular tokens appear: 23268\n"
     ]
    }
   ],
   "source": [
    "# Save dictionary of words and counts to dataframe to enable sorting by count\n",
    "corpus_df = pd.DataFrame(list(corpus.items()), columns = ['word', 'count'])\n",
    "# Sort by count, in descending fashion\n",
    "corpus_df = corpus_df.sort_values(by=['count'],ascending=False)\n",
    "# Sum counts from first 10 rows in sorted dataframe\n",
    "Top10 = sum(corpus_df['count'][0:9])\n",
    "print(\"Total number of times that 10 most popular tokens appear: \" + str(Top10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. The token/type ratio in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of times a specific word is seen (i.e. average number of tokens per type) is 4.580435823754789\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of times a specific word is seen (i.e. average number of tokens per type) is\", len(temp)/len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. The total number of distinct n-grams (of words) that appear in the dataset for n=2,3,4,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 130116 of distinct 2-grams.\n",
      "There are 157675 of distinct 3-grams.\n",
      "There are 153193 of distinct 4-grams.\n",
      "There are 142858 of distinct 5-grams.\n"
     ]
    }
   ],
   "source": [
    "def GramCount(data,n):\n",
    "    i = 0\n",
    "    ngramlist = [] \n",
    "    while i < len(data):\n",
    "        tokens = my_extensible_tokenizer.findall(data['tweet'][i])\n",
    "        grams = list(ngrams(tokens, n)) \n",
    "        for gram in grams:\n",
    "            ngramlist.append(gram)\n",
    "        i += 1\n",
    "    return(len(set(ngramlist)))\n",
    "\n",
    "for i in range(2,6):    \n",
    "      print(\"There are \", GramCount(data,i), \" of distinct \", i,\"-grams.\",sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. The total number of distinct n-grams of characters that appear for n=2,3,4,5,6,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8069 of distinct char 2-grams\n",
      "There are 98192 of distinct char 3-grams\n",
      "There are 212264 of distinct char 4-grams\n",
      "There are 361987 of distinct char 5-grams\n",
      "There are 520197 of distinct char 6-grams\n",
      "There are 662468 of distinct char 7-grams\n"
     ]
    }
   ],
   "source": [
    "# Construct dictionaries that will contain distinct character n-grams\n",
    "n_2 = {}\n",
    "n_3 = {}\n",
    "n_4 = {}\n",
    "n_5 = {}\n",
    "n_6 = {}\n",
    "n_7 = {}\n",
    "\n",
    "# 2. Total number of characters.\n",
    "# 1354375\n",
    "\n",
    "num = 0\n",
    "# Moving through all tweets in the data\n",
    "for tweet in data.values:\n",
    "    # Add to total character count\n",
    "    num += len(tweet[0])\n",
    "    \n",
    "    # Moving through each letter of the tweet...\n",
    "    # Creating distinct character n-grams\n",
    "    for i in range(1,len(tweet[0])):\n",
    "        # Form two-character combos (i.e. n-2 grams)\n",
    "        string2 = tweet[0][i-1:i+1]\n",
    "        # Check whether n-2 gram is already in corpus\n",
    "        if string2 in n_2:\n",
    "            # If already in corpus, add to count\n",
    "            n_2[string2] += 1\n",
    "        # If n-2 gram has not already been seen, add to list\n",
    "        else:\n",
    "            n_2[string2] = 1\n",
    "        # For situations where we are at least 3 characters away from the end-character   \n",
    "        if len(tweet[0]) - i >= 2:\n",
    "            # Form three-character combo\n",
    "            string3 = tweet[0][i-1:i+2]\n",
    "            # Check whether n-3 gram is already in corpus\n",
    "            if string3 in n_3:\n",
    "                # If already in corpus, add to count\n",
    "                n_3[string3] += 1\n",
    "            # If n-3 has not already been seen, add to list\n",
    "            else:\n",
    "                n_3[string3] = 1\n",
    "                \n",
    "        ## Continue equivalently for n-4, n-5, n-6, n-7: check whether we're far\n",
    "        ## enough away from end of tweet to form forward-looking string of that size,\n",
    "        ## save the string, and either save new dict entry or add to dict counter\n",
    "        if len(tweet[0]) - i >= 3:\n",
    "            string4 = tweet[0][i-1:i+3]\n",
    "\n",
    "            if string4 in n_4:\n",
    "                n_4[string4] += 1\n",
    "            # If n-4 gram has not already been seen, add to list\n",
    "            else:\n",
    "                n_4[string4] = 1\n",
    "                \n",
    "        if len(tweet[0]) - i >= 4:\n",
    "            string5 = tweet[0][i-1:i+4]\n",
    "\n",
    "            if string5 in n_5:\n",
    "                n_5[string5] += 1\n",
    "            # If n-5 gram has not already been seen, add to list\n",
    "            else:\n",
    "                n_5[string5] = 1\n",
    "            \n",
    "        if len(tweet[0]) - i >= 5:\n",
    "            string6 = tweet[0][i-1:i+5]\n",
    "\n",
    "            if string6 in n_6:\n",
    "                n_6[string6] += 1\n",
    "            # If n-6 gram has not already been seen, add to list\n",
    "            else:\n",
    "                n_6[string6] = 1\n",
    "                \n",
    "        if len(tweet[0]) - i >= 6:\n",
    "            string7 = tweet[0][i-1:i+6]\n",
    "\n",
    "            if string7 in n_7:\n",
    "                n_7[string7] += 1\n",
    "            # If n-7 gram has not already been seen, add to list\n",
    "            else:\n",
    "                n_7[string7] = 1  \n",
    "\n",
    "print('There are ' + str(len(n_2)) + ' of distinct char 2-grams')\n",
    "print('There are ' + str(len(n_3)) + ' of distinct char 3-grams')\n",
    "print('There are ' + str(len(n_4)) + ' of distinct char 4-grams')\n",
    "print('There are ' + str(len(n_5)) + ' of distinct char 5-grams')\n",
    "print('There are ' + str(len(n_6)) + ' of distinct char 6-grams')\n",
    "print('There are ' + str(len(n_7)) + ' of distinct char 7-grams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Plot a token log frequency. Describe what this plot means and how to interpret it. Describe out it might help you understand coverage when training a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot below shows that a huge majority of words appear with low frequency (n = 1, log(n) = 0). A few words comprise a disproportionately large percentage of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Log(Frequency)')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtain frequency values from dict\n",
    "tok_freqs = list(corpus.values())\n",
    "# Take log of all freq counts\n",
    "log_freqs = [log(x) for x in tok_freqs]\n",
    "# Sort form least to greatest for use in plot\n",
    "log_freqs.sort()\n",
    "# Save list as series to enable plotting\n",
    "logz = pd.Series(log_freqs)\n",
    "# Plot log(freq) of each token, sorted from smallest to largest\n",
    "logz.plot(use_index=False,title='Token Log Frequency')\n",
    "plt.xlabel(\"index(sorted)\")\n",
    "plt.ylabel(\"Log(Frequency)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gold Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of word types that appear in dev data but not training data is 5,062.  \n",
    "Token type ratio is 4.58. \n",
    "\n",
    "The number of distinct words in the input dataset is 41,760.\n",
    "The number of distinct words in the gold dataset is 61,727.\n",
    "\n",
    "The number of positive tweets in the gold dataset is 3,017.\n",
    "The number of neutral tweets in the gold dataset is 2,001.\n",
    "The number of negative tweets in the gold dataset is 850.\n",
    "\n",
    "There is a lot of similarity between the the top words across the three classes. However, we would like to note that \"Donald\", \"Trump\", \"Erdogan\", and \"Jeb\" appear only in the top 50 of the negative tweets. \"Tomorrow\" appears more frequently as tweets get more positive. \"But\" appears less frequently as tweets get more positive. \"Friday\" and \"Jurassic\" appear only in the top 50 of the positive tweets.\"Apple\" appears only in the top 50 of the positive and neutral tweets. Also, \"Amazon\" and \"Prime\" both appear higher in the list of negative tweet frequency than \"Amazon\" does in the list of positive tweet frequencies.\n",
    "\n",
    "The Dev dataset has frequent occurrences of Obama, SCOTUS, Sunday, Minecraft, Snoop, Rick, Sarah, planned, Ric, Palin, Dogg, Netflix, Nike, Serena, and Michelle, which suggests a larger political/pop culture theme for the dev dataset.\n",
    "The training dataset has frequent occurrences of Amazon, Friday, Apple, and night. The two sets are otherwise fairly similar, but the frequent words in the training set more closely match those seen in the overall positive, neutral, and negative subsets, suggesting that the training set is either substantially larger or less niche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data\n",
    "data_dev = pd.read_csv(\"Gold/dev.txt\", sep='\\t', header=None, index_col=False,\n",
    "                   names=['id', 'target', 'tweet'], encoding='utf-8')\n",
    "data_dev.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "data_train = pd.read_csv(\"Gold/train.txt\", sep='\\t', header=None, index_col=False,\n",
    "                   names=['id', 'target', 'tweet'], encoding='utf-8')\n",
    "data_train.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "data_devtest = pd.read_csv(\"Gold/devtest.txt\", sep='\\t', header=None, index_col=False,\n",
    "                           names=['id', 'target', 'tweet'], encoding='utf-8')\n",
    "data_devtest.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "data_test = pd.read_csv(\"Gold/test.txt\", sep='\\t', header=None, index_col=False,\n",
    "                           names=['id', 'target', 'tweet'], encoding='utf-8')\n",
    "data_test.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "# Define list that will hold all token types for Gold dev data\n",
    "temp_gold_dev = []\n",
    "\n",
    "for text in data_dev['tweet'].values:\n",
    "    # Each time the REGEX matches, add the matched string to the running list of all words\n",
    "    for matches in my_extensible_tokenizer.findall(text):\n",
    "         #just in case get empty matches\n",
    "        if matches != '':\n",
    "            # Add string to master list\n",
    "            temp_gold_dev.append(matches)\n",
    "            \n",
    "# Define list that will hold all token types for Gold training data\n",
    "temp_gold_train = []\n",
    "\n",
    "for text in data_train['tweet'].values:\n",
    "    # Each time the REGEX matches, add the matched string to the running list of all words\n",
    "    for matches in my_extensible_tokenizer.findall(text):\n",
    "         #just in case get empty matches\n",
    "        if matches != '':\n",
    "            # Add string to master list\n",
    "            temp_gold_train.append(matches)\n",
    "         \n",
    "                        \n",
    "# Define list that will hold all token types for Gold DEVTEST data\n",
    "temp_gold_devtest = []\n",
    "\n",
    "for text in data_devtest['tweet'].values:\n",
    "    # Each time the REGEX matches, add the matched string to the running list of all words\n",
    "    for matches in my_extensible_tokenizer.findall(text):\n",
    "         #just in case get empty matches\n",
    "        if matches != '':\n",
    "            # Add string to master list\n",
    "            temp_gold_devtest.append(matches)\n",
    "     \n",
    "        \n",
    "# Define list that will hold all token types for Gold test data\n",
    "temp_gold_test = []\n",
    "\n",
    "for text in data_test['tweet'].values:\n",
    "    # Each time the REGEX matches, add the matched string to the running list of all words\n",
    "    for matches in my_extensible_tokenizer.findall(text):\n",
    "         #just in case get empty matches\n",
    "        if matches != '':\n",
    "            # Add string to master list\n",
    "            temp_gold_test.append(matches)\n",
    "\n",
    "\n",
    "# Create null dictionaries that will store types and counts for each dataset\n",
    "corpus_gold_dev = {}\n",
    "corpus_gold_train = {}\n",
    "corpus_gold_devtest = {}\n",
    "corpus_gold_test = {}\n",
    "# Create null dictionary that will store types and counts for all gold datasets combined\n",
    "corpus_gold = {}\n",
    "\n",
    "# Looking through entire list of (repeated) words, count instances of distinct words\n",
    "for word in temp_gold_dev:\n",
    "    # If word has already been seen, add one to its count\n",
    "    if word in corpus_gold_dev:\n",
    "        corpus_gold_dev[word] += 1\n",
    "    # If word has not already been seen, add word to list\n",
    "    else:\n",
    "        corpus_gold_dev[word] = 1\n",
    "    if word in corpus_gold:\n",
    "        corpus_gold[word] += 1\n",
    "    else:\n",
    "        corpus_gold[word] = 1\n",
    "# Number of unique words in dev set\n",
    "unique1 = len(corpus_gold)\n",
    "\n",
    "# Looking through entire list of (repeated) words, count instances of distinct words\n",
    "for word in temp_gold_train:\n",
    "    # If word has already been seen, add one to its count\n",
    "    if word in corpus_gold_train:\n",
    "        corpus_gold_train[word] += 1\n",
    "    # If word has not already been seen, add word to list\n",
    "    else:\n",
    "        corpus_gold_train[word] = 1\n",
    "        \n",
    "    if word in corpus_gold:\n",
    "        corpus_gold[word] += 1\n",
    "    else:\n",
    "        corpus_gold[word] = 1\n",
    "# Number of unique words in training set\n",
    "unique2 = len(corpus_gold)\n",
    "\n",
    "# Looking through entire list of (repeated) words, count instances of distinct words\n",
    "for word in temp_gold_devtest:\n",
    "    # If word has already been seen, add one to its count\n",
    "    if word in corpus_gold_devtest:\n",
    "        corpus_gold_devtest[word] += 1\n",
    "    # If word has not already been seen, add word to list\n",
    "    else:\n",
    "        corpus_gold_devtest[word] = 1\n",
    "\n",
    "    if word in corpus_gold:\n",
    "        corpus_gold[word] += 1\n",
    "    else:\n",
    "        corpus_gold[word] = 1       \n",
    "# Number of unique words in devtest set\n",
    "unique3 = len(corpus_gold)\n",
    "\n",
    "# Looking through entire list of (repeated) words, count instances of distinct words\n",
    "for word in temp_gold_test:\n",
    "    # If word has already been seen, add one to its count\n",
    "    if word in corpus_gold_test:\n",
    "        corpus_gold_test[word] += 1\n",
    "    # If word has not already been seen, add word to list\n",
    "    else:\n",
    "        corpus_gold_test[word] = 1\n",
    "\n",
    "    if word in corpus_gold:\n",
    "        corpus_gold[word] += 1\n",
    "    else:\n",
    "        corpus_gold[word] = 1     \n",
    "# Number of unique words in test set\n",
    "unique4 = len(corpus_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the number of types that appear in the dev data but not the training data (OOV)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of types found in dev data but not in training data: 5062\n"
     ]
    }
   ],
   "source": [
    "# Define variable that will store values found in exclusively the dev data\n",
    "justdev = corpus_gold_dev.keys() - corpus_gold_train.keys()\n",
    "print('Number of types found in dev data but not in training data: ' + str(len(justdev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Look at the vocabulary growth (types) combining your four gold data sets against your input data. Plot vocabulary growth at difference sample sizes N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct words in input dataset: 41760\n",
      "Distinct words in gold dataset: 61727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Unique Words in Lexicon')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Distinct words in input dataset: \" + str(len(corpus)) + \"\\nDistinct words in gold dataset: \" + str(len(corpus_gold)))\n",
    "\n",
    "# Save number of tokens in dev set\n",
    "full1 = len(temp_gold_dev)\n",
    "# Save number of tokens in training set        \n",
    "full2 = len(temp_gold_train)   \n",
    "# Save number of tokens in devset   \n",
    "full3 = len(temp_gold_devtest) \n",
    "# Save number of tokens in test set\n",
    "full4 = len(temp_gold_test)\n",
    "\n",
    "lexicon = pd.DataFrame({'unique':[0,unique1,unique2,unique3,unique4],'total':[0,full1,full1+full2,full1+full2+full3,full1+full2+full3+full4]})\n",
    "lexicon.plot(x ='total', y='unique', kind = 'line', title='Gold Dataset',marker='.', markersize=15,legend=None)\n",
    "plt.xlabel(\"Total Number of Words\")\n",
    "plt.ylabel(\"Unique Words in Lexicon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. What is the class distribution of the training data set - how many negative, neutral, positive tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Number of Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>3017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class  Number of Tweets\n",
       "0   neutral              2001\n",
       "1  negative               850\n",
       "2  positive              3017"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unique values of the class column for the training data set\n",
    "uniqgold = set(data_train['target']) \n",
    "\n",
    "numuniq = []\n",
    "for value in uniqgold:\n",
    "    count = 0\n",
    "    for value2 in data_train['target']:\n",
    "        if value2 == value:\n",
    "            count += 1\n",
    "    numuniq.append(count)\n",
    "\n",
    "uniqlist = {'Class':list(uniqgold), 'Number of Tweets': numuniq}\n",
    "uniqdf = pd.DataFrame(uniqlist)\n",
    "uniqdf   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Look at the difference between the top word types across these three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>on</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>in</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>a</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on</td>\n",
       "      <td>and</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>I</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for</td>\n",
       "      <td>is</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>for</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>with</td>\n",
       "      <td>may</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>you</td>\n",
       "      <td>with</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>be</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>be</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>at</td>\n",
       "      <td>it</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>may</td>\n",
       "      <td>at</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>it</td>\n",
       "      <td>have</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>th</td>\n",
       "      <td>tomorrow</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>my</td>\n",
       "      <td>th</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>have</td>\n",
       "      <td>that</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>but</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>this</td>\n",
       "      <td>1</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>my</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>just</td>\n",
       "      <td>will</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>see</td>\n",
       "      <td>2</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>that</td>\n",
       "      <td>not</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>was</td>\n",
       "      <td>was</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>will</td>\n",
       "      <td>just</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I'm</td>\n",
       "      <td>he</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>amp</td>\n",
       "      <td>me</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>but</td>\n",
       "      <td>from</td>\n",
       "      <td>tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>going</td>\n",
       "      <td>st</td>\n",
       "      <td>st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>day</td>\n",
       "      <td>this</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>all</td>\n",
       "      <td>about</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>me</td>\n",
       "      <td>or</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Friday</td>\n",
       "      <td>going</td>\n",
       "      <td>Prime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>time</td>\n",
       "      <td>Apple</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>night</td>\n",
       "      <td>as</td>\n",
       "      <td>I'm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>The</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>st</td>\n",
       "      <td>3</td>\n",
       "      <td>amp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>about</td>\n",
       "      <td>out</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>The</td>\n",
       "      <td>so</td>\n",
       "      <td>Donald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>from</td>\n",
       "      <td>like</td>\n",
       "      <td>Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>an</td>\n",
       "      <td>Erdogan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Jurassic</td>\n",
       "      <td>amp</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>out</td>\n",
       "      <td>5</td>\n",
       "      <td>going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Apple</td>\n",
       "      <td>if</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>new</td>\n",
       "      <td>get</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>so</td>\n",
       "      <td>Google</td>\n",
       "      <td>Jeb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pos       neu       neg\n",
       "0        the       the       the\n",
       "1         to        to        to\n",
       "2          I        on         a\n",
       "3          a        in         I\n",
       "4        and         a        is\n",
       "5         on       and        on\n",
       "6         in         I       and\n",
       "7         of        of        of\n",
       "8        for        is        in\n",
       "9         is       for       may\n",
       "10      with       may        be\n",
       "11       you      with        it\n",
       "12  tomorrow        be       for\n",
       "13        be       you       you\n",
       "14        at        it        my\n",
       "15       may        at      with\n",
       "16        it      have       but\n",
       "17        th  tomorrow      that\n",
       "18        my        th      have\n",
       "19      have      that       not\n",
       "20         1       but        th\n",
       "21      this         1      just\n",
       "22         2        my         1\n",
       "23      just      will      like\n",
       "24       see         2    Amazon\n",
       "25      that       not      this\n",
       "26       was       was        at\n",
       "27      will      just       was\n",
       "28       I'm        he     about\n",
       "29       amp        me         3\n",
       "30       but      from  tomorrow\n",
       "31     going        st        st\n",
       "32       day      this        he\n",
       "33       all     about      will\n",
       "34        me        or        me\n",
       "35    Friday     going     Prime\n",
       "36      time     Apple         2\n",
       "37     night        as       I'm\n",
       "38    Amazon       The        as\n",
       "39        st         3       amp\n",
       "40     about       out        so\n",
       "41         5       I'm       his\n",
       "42       The        so    Donald\n",
       "43      from      like     Trump\n",
       "44         3        an   Erdogan\n",
       "45  Jurassic       amp       all\n",
       "46       out         5     going\n",
       "47     Apple        if       Day\n",
       "48       new       get        up\n",
       "49        so    Google       Jeb"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = data_train[data_train['target'] == 'positive']\n",
    "neutral = data_train[data_train['target'] == 'neutral']\n",
    "negative = data_train[data_train['target'] == 'negative']\n",
    "\n",
    "temp_pos = []\n",
    "for text in positive['tweet'].values:\n",
    "    # Each time the REGEX matches, add the matched string to the running list of all words\n",
    "    for matches in my_extensible_tokenizer.findall(text):\n",
    "         #just in case get empty matches\n",
    "        if matches != '':\n",
    "            # Add string to master list\n",
    "            temp_pos.append(matches)\n",
    "\n",
    "temp_neu = []\n",
    "for text in neutral['tweet'].values:\n",
    "    # Each time the REGEX matches, add the matched string to the running list of all words\n",
    "    for matches in my_extensible_tokenizer.findall(text):\n",
    "         #just in case get empty matches\n",
    "        if matches != '':\n",
    "            # Add string to master list\n",
    "            temp_neu.append(matches)\n",
    " \n",
    "temp_neg = []\n",
    "for text in negative['tweet'].values:\n",
    "    # Each time the REGEX matches, add the matched string to the running list of all words\n",
    "    for matches in my_extensible_tokenizer.findall(text):\n",
    "         #just in case get empty matches\n",
    "        if matches != '':\n",
    "            # Add string to master list\n",
    "            temp_neg.append(matches)\n",
    "\n",
    "corpus_pos = {}\n",
    "# Looking through entire list of (repeated) words, count instances of distinct words\n",
    "for word in temp_pos:\n",
    "    # If word has already been seen, add one to its count\n",
    "    if word in corpus_pos:\n",
    "        corpus_pos[word] += 1\n",
    "    # If word has not already been seen, add word to list\n",
    "    else:\n",
    "        corpus_pos[word] = 1\n",
    "    \n",
    "pos_df = pd.DataFrame(list(corpus_pos.items()), columns = ['word', 'count'])\n",
    "# Sort by count, in descending fashion\n",
    "pos_df = pos_df.sort_values(by=['count'],ascending=False)\n",
    "   \n",
    "corpus_neu = {}\n",
    "# Looking through entire list of (repeated) words, count instances of distinct words\n",
    "for word in temp_neu:\n",
    "    # If word has already been seen, add one to its count\n",
    "    if word in corpus_neu:\n",
    "        corpus_neu[word] += 1\n",
    "    # If word has not already been seen, add word to list\n",
    "    else:\n",
    "        corpus_neu[word] = 1\n",
    "\n",
    "neu_df = pd.DataFrame(list(corpus_neu.items()), columns = ['word', 'count'])\n",
    "# Sort by count, in descending fashion\n",
    "neu_df = neu_df.sort_values(by=['count'],ascending=False)\n",
    "\n",
    "\n",
    "corpus_neg = {}\n",
    "# Looking through entire list of (repeated) words, count instances of distinct words\n",
    "for word in temp_neg:\n",
    "    # If word has already been seen, add one to its count\n",
    "    if word in corpus_neg:\n",
    "        corpus_neg[word] += 1\n",
    "    # If word has not already been seen, add word to list\n",
    "    else:\n",
    "        corpus_neg[word] = 1\n",
    "\n",
    "neg_df = pd.DataFrame(list(corpus_neg.items()), columns = ['word', 'count'])\n",
    "# Sort by count, in descending fashion\n",
    "neg_df = neg_df.sort_values(by=['count'],ascending=False)\n",
    "\n",
    "Top51 = pd.DataFrame()\n",
    "Top51['pos'] = pos_df['word'].values[0:50]\n",
    "Top51['neu'] = neu_df['word'].values[0:50]\n",
    "Top51['neg'] = neg_df['word'].values[0:50]\n",
    "Top51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. What words are particularly characteristic of your training set and dev set? Are they the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>with</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>you</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>be</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>may</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>at</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>it</td>\n",
       "      <td>th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>th</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>my</td>\n",
       "      <td>tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>have</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>that</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>but</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>just</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>was</td>\n",
       "      <td>st</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>will</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>this</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>not</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>me</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I'm</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>going</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>st</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>amp</td>\n",
       "      <td>amp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>about</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>he</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>from</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>all</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>day</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>see</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>time</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>like</td>\n",
       "      <td>SCOTUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>The</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Friday</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>out</td>\n",
       "      <td>Minecraft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>as</td>\n",
       "      <td>Snoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>so</td>\n",
       "      <td>Rick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>Sarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Planned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>up</td>\n",
       "      <td>Ric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>get</td>\n",
       "      <td>Palin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>are</td>\n",
       "      <td>Dogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>nd</td>\n",
       "      <td>going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>or</td>\n",
       "      <td>Pride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>night</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>Nike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>if</td>\n",
       "      <td>Serena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>an</td>\n",
       "      <td>Michelle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train        dev\n",
       "0        the        the\n",
       "1         to         to\n",
       "2          a          I\n",
       "3         on          a\n",
       "4          I         on\n",
       "5        and        and\n",
       "6         in         in\n",
       "7         of         of\n",
       "8        for         is\n",
       "9         is         be\n",
       "10      with        may\n",
       "11       you        for\n",
       "12        be        you\n",
       "13       may       with\n",
       "14        at         it\n",
       "15  tomorrow         at\n",
       "16        it         th\n",
       "17        th       that\n",
       "18        my   tomorrow\n",
       "19      have       have\n",
       "20      that          1\n",
       "21       but        was\n",
       "22         1      Obama\n",
       "23      just         my\n",
       "24         2       will\n",
       "25       was         st\n",
       "26      will        but\n",
       "27      this          2\n",
       "28       not       just\n",
       "29        me       this\n",
       "30       I'm        The\n",
       "31     going          3\n",
       "32        st        not\n",
       "33       amp        amp\n",
       "34     about      about\n",
       "35        he        out\n",
       "36      from       like\n",
       "37         3        I'm\n",
       "38       all         as\n",
       "39    Amazon       from\n",
       "40       day       time\n",
       "41       see         he\n",
       "42      time        all\n",
       "43      like     SCOTUS\n",
       "44       The     Sunday\n",
       "45    Friday         so\n",
       "46       out  Minecraft\n",
       "47        as      Snoop\n",
       "48        so       Rick\n",
       "49         5      Sarah\n",
       "50     Apple    Planned\n",
       "51        up        Ric\n",
       "52       get      Palin\n",
       "53       are       Dogg\n",
       "54        nd      going\n",
       "55        or      Pride\n",
       "56     night    Netflix\n",
       "57         4       Nike\n",
       "58        if     Serena\n",
       "59        an   Michelle"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save training dictionary to dataframe so that it can be ordered by count\n",
    "train_df = pd.DataFrame(list(corpus_gold_train.items()), columns = ['word', 'count'])\n",
    "# Sort by count, in descending fashion\n",
    "train_df = train_df.sort_values(by=['count'],ascending=False)\n",
    "\n",
    "# Save dev dictionary to dataframe so that it can be ordered by count\n",
    "dev_df = pd.DataFrame(list(corpus_gold_dev.items()), columns = ['word', 'count'])\n",
    "# Sort by count, in descending fashion\n",
    "dev_df = dev_df.sort_values(by=['count'],ascending=False)\n",
    "\n",
    "Top61 = pd.DataFrame()\n",
    "Top61['train'] = train_df['word'].values[0:60]\n",
    "Top61['dev'] = dev_df['word'].values[0:60]\n",
    "Top61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Message Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
